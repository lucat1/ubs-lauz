{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load(p: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(p)\n",
    "    df['transaction_reference_id'] = df['transaction_reference_id'].apply(lambda x: int(x, 16))\n",
    "    return df\n",
    "\n",
    "account_booking_test_ = load(\"account_booking_test.csv\")\n",
    "account_booking_train_ = load(\"account_booking_train.csv\")\n",
    "external_parties_test_ = load(\"external_parties_test.csv\")\n",
    "external_parties_train_ = load(\"external_parties_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(line):\n",
    "    return line.lower() \\\n",
    "        .replace('mr', '') \\\n",
    "        .replace('ms', '') \\\n",
    "        .replace('mrs', '') \\\n",
    "        .replace('miss ', '') \\\n",
    "        .replace('dr', '') \\\n",
    "        .replace('prof', '') \\\n",
    "        .replace('rev', '') \\\n",
    "        .replace('hon', '') \\\n",
    "        .replace('.', '')\n",
    "\n",
    "def clean_data_phone(line):\n",
    "    if type(line) == str and line != \"nan\":\n",
    "        return line.lower().replace('+', '').replace('-', '').replace('(', '').replace(')', '').replace(' ', '').replace(',', '').replace('.', '')\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def clean_data_iban(line):\n",
    "    if type(line) == str and line != \"nan\":\n",
    "        return line\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def cleanup(df: pd.DataFrame):\n",
    "    df[\"party_iban\"] = df[\"party_iban\"].apply(clean_data_iban)\n",
    "    df[\"parsed_name\"] = df[\"parsed_name\"].apply(clean_data)\n",
    "    df[\"party_phone\"] = df[\"party_phone\"].apply(clean_data_phone)\n",
    "\n",
    "cleanup(external_parties_train_)\n",
    "cleanup(external_parties_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if training d\n",
    "if False:\n",
    "    account_booking = account_booking_train_\n",
    "    external_parties = external_parties_train_\n",
    "else:\n",
    "    account_booking = account_booking_test_\n",
    "    external_parties = external_parties_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_internal(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.drop_duplicates(subset=[\"transaction_reference_id\"], keep=False)\n",
    "\n",
    "account_booking = remove_internal(account_booking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert account_booking.dtypes['transaction_reference_id'] == external_parties.dtypes['transaction_reference_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = external_parties.set_index('transaction_reference_id').join(\n",
    "    account_booking.set_index('transaction_reference_id'),\n",
    "    on='transaction_reference_id'\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(joined[pd.isna(joined['parsed_name'])]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simhash import Simhash\n",
    "from datetime import date\n",
    "import pickle\n",
    "from math import isnan\n",
    "\n",
    "d_name = {}\n",
    "d_city = {}\n",
    "\n",
    "with open(\"d_name.pkl\" , 'rb') as f:\n",
    "    d_name = pickle.load(f)\n",
    "with open(\"d_city.pkl\" , 'rb') as f:\n",
    "    d_city = pickle.load(f)\n",
    "    \n",
    "# parsed_name\n",
    "# parsed_address_street_name\n",
    "# parsed_address_street_number\n",
    "# parsed_address_unit\n",
    "# parsed_address_postal_code\n",
    "# parsed_address_city\n",
    "# parsed_address_state\n",
    "# parsed_address_country\n",
    "# party_iban\n",
    "# party_phone\n",
    "\n",
    "\n",
    "def bucket_iban(df: pd.DataFrame) -> int | None:\n",
    "    return df['party_iban']\n",
    "\n",
    "def bucket_street_number(df: pd.DataFrame) -> int | None:\n",
    "    return df['parsed_address_street_number']\n",
    "\n",
    "def bucket_unit(df: pd.DataFrame) -> int | None:\n",
    "    return df['parsed_address_unit']\n",
    "\n",
    "def bucket_address_state(df: pd.DataFrame) -> int | None:\n",
    "    return df['parsed_address_state']\n",
    "\n",
    "def bucket_address_country(df: pd.DataFrame) -> int | None:\n",
    "    return df['parsed_address_country']\n",
    "\n",
    "def bucket_hname(df: pd.DataFrame) -> int | None:\n",
    "    # parsed_name = df['parsed_name']\n",
    "    # return Simhash(parsed_name).value\n",
    "    # return df['parsed_name']\n",
    "    return d_name[df['transaction_reference_id']]\n",
    "\n",
    "def bucket_name(df: pd.DataFrame) -> int | None:\n",
    "    # parsed_name = df['parsed_name']\n",
    "    # return Simhash(parsed_name).value\n",
    "    return df['parsed_name']\n",
    "    # return d_name[df['transaction_reference_id']]\n",
    "\n",
    "def bucket_city(df: pd.DataFrame) -> int | None:\n",
    "    return df['parsed_address_city']\n",
    "\n",
    "def bucket_postal_code(df: pd.DataFrame) -> int | None:\n",
    "    return df['parsed_address_postal_code']\n",
    "\n",
    "def bucket_date(df: pd.DataFrame) -> int | None:\n",
    "    return date.fromisoformat(df['transaction_date']).day\n",
    "\n",
    "def bucket_name_street(df: pd.DataFrame) -> int | None:\n",
    "    if has_field(df, 'parsed_address_street_name'):\n",
    "        parsed_name = df['parsed_name']\n",
    "        street = df['parsed_address_street_name']\n",
    "        street = 0 if (type(street) == float and isnan(street)) else str(street)\n",
    "        return f\"{Simhash(parsed_name).value}-{street}\"\n",
    "    else:\n",
    "        return f\"{df['transaction_reference_id']}\"\n",
    "    \n",
    "def has_field(df: pd.DataFrame, field: str) -> bool:\n",
    "    # P => Q == not P or Q\n",
    "    if field not in df:\n",
    "        return False\n",
    "\n",
    "    val = df[field]\n",
    "    return val is not None and (type(val) == str or not isnan(val)) and (type(val) != str or val != \"\")\n",
    "\n",
    "def bucket_name_address(df: pd.DataFrame) -> int | None:\n",
    "    return f\"{bucket_name(df)}-{bucket_address(df)}\"\n",
    "\n",
    "def bucket_hname_address(df: pd.DataFrame) -> int | None:\n",
    "    return f\"{bucket_hname(df)}-{bucket_address(df)}\"\n",
    "\n",
    "def bucket_name_paddress(df: pd.DataFrame) -> int | None:\n",
    "    return f\"{bucket_name(df)}-{bucket_address_partial1(df)}\"\n",
    "\n",
    "def bucket_name_state(df: pd.DataFrame) -> int | None:\n",
    "    return f\"{bucket_name(df)}-{bucket_address_state(df)}\"\n",
    "\n",
    "def bucket_phone(df: pd.DataFrame) -> int | None:\n",
    "    if has_field(df, 'party_phone'):\n",
    "        return df['party_phone']\n",
    "    else:\n",
    "        return df['transaction_reference_id']\n",
    "\n",
    "def bucket_address(df: pd.DataFrame) -> int | None:\n",
    "    if has_field(df, 'parsed_address_street_number') and has_field(df, 'parsed_address_street_name') and has_field(df, 'parsed_address_city') and has_field(df, 'parsed_address_postal_code'):\n",
    "        num = df['parsed_address_street_number']\n",
    "        street = df['parsed_address_street_name']\n",
    "        city = df['parsed_address_city']\n",
    "        code = df['parsed_address_postal_code']\n",
    "        state = df['parsed_address_state']\n",
    "        return f\"{num}-{Simhash(street).value}-{city}-{state}-{code}\"\n",
    "    else:\n",
    "        return df['transaction_reference_id']\n",
    "    \n",
    "def bucket_address_partial1(df: pd.DataFrame) -> int | None:\n",
    "    if has_field(df, 'parsed_address_city') and has_field(df, 'parsed_address_postal_code'):\n",
    "        city = df['parsed_address_city']\n",
    "        code = df['parsed_address_postal_code']\n",
    "        state = df['parsed_address_state']\n",
    "        return f\"{city}-{state}-{code}\"\n",
    "    else:\n",
    "        return df['transaction_reference_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any, Dict\n",
    "from datetime import datetime\n",
    "\n",
    "def add_linear_id(start_idx: int, df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['external_id'] = range(start_idx, start_idx + len(df))\n",
    "    return df\n",
    "\n",
    "# runs the provided functions on the dataframe and progressively groups using a function\n",
    "# at a time. Returns a dataframe where all rows have been grouped with an associated ID,\n",
    "# and a dataframe with still ungrouped rows.\n",
    "def bucket_by_fn(df: pd.DataFrame, fns: List[Any]) -> pd.DataFrame:\n",
    "    already_grouped = pd.DataFrame()\n",
    "    for fn in fns:\n",
    "        df['bucket'] = df.apply(fn, axis=1)\n",
    "        grouped_ids = df.groupby('bucket', dropna=True).filter(lambda x: len(x) > 1)\n",
    "        grouped_ids['external_id'] = grouped_ids.groupby('bucket', dropna=True).ngroup() + len(df)\n",
    "        new_group = grouped_ids[['transaction_reference_id', 'external_id']]\n",
    "        already_grouped = pd.concat([already_grouped, new_group])\n",
    "        df = df.drop(['bucket'], axis=1)\n",
    "        df = df[~df['transaction_reference_id'].isin(already_grouped['transaction_reference_id'])]\n",
    "        print(f\"fn {fn} applied\")\n",
    "        \n",
    "    already_grouped['transaction_reference_id'] = already_grouped['transaction_reference_id'].apply(lambda x: f\"{x:0{32}x}\")\n",
    "    return already_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_thing(booking: pd.DataFrame, external: pd.DataFrame) -> pd.DataFrame:\n",
    "    assert len(external[pd.isna(external['parsed_name'])]) == 0\n",
    "\n",
    "    joined = external.set_index('transaction_reference_id').join(\n",
    "        booking.set_index('transaction_reference_id'),\n",
    "        on='transaction_reference_id'\n",
    "    ).reset_index()\n",
    "    print('join finished, working on', len(joined), 'elements')\n",
    "    assert len(joined[pd.isna(joined['parsed_name'])]) == 0\n",
    "\n",
    "    final = bucket_by_fn(joined, [bucket_iban, bucket_address, bucket_address_partial1, bucket_phone])\n",
    "    print(f\"found {len(final)} tuples\")\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "join finished, working on 1481672 elements\n",
      "fn <function bucket_iban at 0x7080adb6eac0> applied\n",
      "fn <function bucket_name_address at 0x708034475580> applied\n",
      "fn <function bucket_name_state at 0x7080344767a0> applied\n"
     ]
    }
   ],
   "source": [
    "df = do_thing(account_booking_test_, external_parties_test_)\n",
    "# df = do_thing(account_booking_train_, external_parties_train_)\n",
    "df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entities:  6428 / 8093\n",
      "Number of groups:  2017 / 2029\n",
      "0.6615760266370699\n"
     ]
    }
   ],
   "source": [
    "def compare(inp: pd.DataFrame, truth: pd.DataFrame):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "    \n",
    "    truth_map = {}\n",
    "    guess_map = {}\n",
    "    for _, x in truth.iterrows():\n",
    "        truth_map[x[\"transaction_reference_id\"]] = x[\"external_id\"]\n",
    "    \n",
    "    for _, x in inp.iterrows():\n",
    "        guess_map[x[\"transaction_reference_id\"]] = x[\"external_id\"]\n",
    "\n",
    "    inp = inp[inp.duplicated(subset='external_id', keep=False)]\n",
    "    truth = truth[truth.duplicated(subset='external_id', keep=False)]\n",
    "\n",
    "    truth_gr = truth.groupby(\"external_id\")[\"transaction_reference_id\"].apply(list)\n",
    "    guess_gr = inp.groupby(\"external_id\")[\"transaction_reference_id\"].apply(list)\n",
    "\n",
    "    for t_group in truth_gr:\n",
    "        for a in t_group:\n",
    "            for b in t_group:\n",
    "                if a == b:\n",
    "                    continue\n",
    "\n",
    "                ag, bg = guess_map.get(a), guess_map.get(b)\n",
    "\n",
    "                if (ag and bg) and ag == bg:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fn += 1\n",
    "\n",
    "    for g_group in guess_gr:\n",
    "        for a in g_group:\n",
    "            for b in g_group:\n",
    "                if a == b:\n",
    "                    continue\n",
    "                \n",
    "                at, bt = truth_map[a], truth_map[b]\n",
    "\n",
    "                if at != bt:\n",
    "                    fp += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "    \n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    \n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "removed_singleton = external_parties_train_[external_parties_train_.duplicated(subset='external_id', keep=False)]\n",
    "print(\"Number of entities: \", len(df), \"/\", len(removed_singleton))\n",
    "print(\"Number of groups: \", len(df.groupby('external_id').count()), \"/\", len(removed_singleton.groupby('external_id').count()))\n",
    "# result = do_thing(account_booking_train_, external_parties_train_)\n",
    "df['transaction_reference_id'] = df['transaction_reference_id'].apply(lambda x: int(x, 16))\n",
    "print(compare(df, external_parties_train_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_reference_id</th>\n",
       "      <th>external_id</th>\n",
       "      <th>party_role</th>\n",
       "      <th>party_info_unstructured</th>\n",
       "      <th>parsed_name</th>\n",
       "      <th>parsed_address_street_name</th>\n",
       "      <th>parsed_address_street_number</th>\n",
       "      <th>parsed_address_unit</th>\n",
       "      <th>parsed_address_postal_code</th>\n",
       "      <th>parsed_address_city</th>\n",
       "      <th>parsed_address_state</th>\n",
       "      <th>parsed_address_country</th>\n",
       "      <th>party_iban</th>\n",
       "      <th>party_phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4756</th>\n",
       "      <td>329607983514487012669631641585391708093</td>\n",
       "      <td>6342</td>\n",
       "      <td>BENE</td>\n",
       "      <td>b. johnson 177 sherry corner haleyfort</td>\n",
       "      <td>b johnson</td>\n",
       "      <td>sherry corner</td>\n",
       "      <td>177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>haleyfort</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>004100127881000747212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4790</th>\n",
       "      <td>101892866522542013383394373256733168479</td>\n",
       "      <td>6342</td>\n",
       "      <td>BENE</td>\n",
       "      <td>bradley johnson 177 sherry corner haleyfort</td>\n",
       "      <td>bradley johnson</td>\n",
       "      <td>sherry corner</td>\n",
       "      <td>177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>haleyfort</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>004100127881000747212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     transaction_reference_id  external_id party_role  \\\n",
       "4756  329607983514487012669631641585391708093         6342       BENE   \n",
       "4790  101892866522542013383394373256733168479         6342       BENE   \n",
       "\n",
       "                          party_info_unstructured      parsed_name  \\\n",
       "4756       b. johnson 177 sherry corner haleyfort        b johnson   \n",
       "4790  bradley johnson 177 sherry corner haleyfort  bradley johnson   \n",
       "\n",
       "     parsed_address_street_name parsed_address_street_number  \\\n",
       "4756              sherry corner                          177   \n",
       "4790              sherry corner                          177   \n",
       "\n",
       "      parsed_address_unit parsed_address_postal_code parsed_address_city  \\\n",
       "4756                  NaN                        NaN           haleyfort   \n",
       "4790                  NaN                        NaN           haleyfort   \n",
       "\n",
       "     parsed_address_state parsed_address_country party_iban  \\\n",
       "4756                  NaN                    NaN       None   \n",
       "4790                  NaN                    NaN       None   \n",
       "\n",
       "                party_phone  \n",
       "4756  004100127881000747212  \n",
       "4790  004100127881000747212  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = df.set_index('transaction_reference_id').join(\n",
    "        external_parties_train_.drop('external_id', axis=1).set_index('transaction_reference_id'),\n",
    "        on='transaction_reference_id'\n",
    "    ).reset_index().groupby('external_id')\n",
    "\n",
    "g = pd.DataFrame()\n",
    "for i, grp in groups:\n",
    "    g = pd.concat([g, grp])\n",
    "    if i > 4:\n",
    "        break\n",
    "\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "join finished, working on 11064 elements\n",
      "fn <function bucket_iban at 0x7ff7b1508040> applied\n",
      "found 3872 tuples\n"
     ]
    }
   ],
   "source": [
    "result = do_thing(account_booking_train_, external_parties_train_)\n",
    "df = pd.DataFrame(list(result.items()), columns=['transaction_reference_id', 'external_id'])\n",
    "df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "external_id                                                              20000042\n",
      "transaction_reference_id        [313980040502377422398921352947482856636, 1670...\n",
      "debit_credit_indicator                                   [CREDIT, CREDIT, CREDIT]\n",
      "account_id                                                  [28523, 25210, 21675]\n",
      "transaction_amount                                    [8101.48, 5879.79, 4590.15]\n",
      "transaction_currency                                              [GBP, GBP, GBP]\n",
      "transaction_date                             [2023-07-10, 2023-06-02, 2024-10-24]\n",
      "party_role                                                        [ORG, ORG, ORG]\n",
      "party_info_unstructured         [m. solomon 08/04/2000 826 gwendolyn plaza apt...\n",
      "parsed_name                         [m solomon, marsolomon, mary mary solomon ii]\n",
      "parsed_address_street_name      [gwendolyn plaza, gwendolyn plaza apt., gwendo...\n",
      "parsed_address_street_number                                      [826, 826, 826]\n",
      "parsed_address_unit                                               [nan, nan, nan]\n",
      "parsed_address_postal_code                                  [61961, 61961, 61961]\n",
      "parsed_address_city                          [robertberg, robertberg, robertberg]\n",
      "parsed_address_state                                              [nan, nan, nan]\n",
      "parsed_address_country           [united kingdom, united kingdom, united kingdom]\n",
      "party_iban                                     [nan, nan, GB38UAQB86888977965671]\n",
      "party_phone                         [(+ 41)271367-3164, (0041)+1558_3764686, nan]\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "booking = pd.DataFrame(account_booking_train_).drop_duplicates(subset=[\"transaction_reference_id\"], keep=False)\n",
    "parties = external_parties_train_[external_parties_train_.duplicated(subset=\"external_id\", keep=False)]\n",
    "data = booking.merge(parties, on=\"transaction_reference_id\", how=\"inner\").groupby('external_id').agg(list).reset_index()\n",
    "print(data.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lauz-NrUmdOLo-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
